from __future__ import annotations

import argparse
import csv
import math
from dataclasses import dataclass
from datetime import UTC, datetime
from pathlib import Path


@dataclass(slots=True)
class ScenarioResult:
    scenario: str
    request_count: int
    failure_count: int
    p50_ms: float
    p95_ms: float
    p99_ms: float
    throughput_rps: float


def _to_float(value: str | None) -> float:
    if value is None:
        return math.nan
    normalized = value.strip()
    if not normalized:
        return math.nan
    return float(normalized)


def _to_int(value: str | None) -> int:
    if value is None:
        return 0
    normalized = value.strip()
    if not normalized:
        return 0
    return int(float(normalized))


def _scenario_from_file(stats_file: Path) -> str:
    stem = stats_file.stem
    if stem.endswith("_stats"):
        return stem.removesuffix("_stats")
    return stem


def _load_scenario_result(stats_file: Path) -> ScenarioResult:
    with stats_file.open("r", encoding="utf-8-sig", newline="") as handle:
        reader = csv.DictReader(handle)
        for row in reader:
            row_type = (row.get("Type") or "").strip()
            row_name = (row.get("Name") or "").strip()
            if row_type == "Aggregated" or row_name == "Aggregated":
                p50_ms = _to_float(row.get("50%"))
                if math.isnan(p50_ms):
                    p50_ms = _to_float(row.get("Median Response Time"))

                return ScenarioResult(
                    scenario=_scenario_from_file(stats_file),
                    request_count=_to_int(row.get("Request Count")),
                    failure_count=_to_int(row.get("Failure Count")),
                    p50_ms=p50_ms,
                    p95_ms=_to_float(row.get("95%")),
                    p99_ms=_to_float(row.get("99%")),
                    throughput_rps=_to_float(row.get("Requests/s")),
                )
    raise ValueError(f"No aggregated row found in {stats_file}")


def _format_float(value: float) -> str:
    if math.isnan(value):
        return "n/a"
    return f"{value:.2f}"


def _build_markdown(results: list[ScenarioResult], threshold_ms: float) -> str:
    lines: list[str] = []
    lines.append("# Performance Test Report")
    lines.append("")
    lines.append(f"- Generated at: {datetime.now(UTC).isoformat()}")
    lines.append(f"- P95 threshold: {threshold_ms:.2f} ms")
    lines.append("")
    lines.append(
        "| Scenario | Requests | Failures | p50 (ms) | p95 (ms) | p99 (ms) | Throughput (req/s) | Status |"
    )
    lines.append(
        "| --- | ---: | ---: | ---: | ---: | ---: | ---: | --- |"
    )

    for result in results:
        passed = result.failure_count == 0 and not math.isnan(result.p95_ms) and result.p95_ms <= threshold_ms
        status = "PASS" if passed else "FAIL"
        lines.append(
            "| "
            f"{result.scenario} | "
            f"{result.request_count} | "
            f"{result.failure_count} | "
            f"{_format_float(result.p50_ms)} | "
            f"{_format_float(result.p95_ms)} | "
            f"{_format_float(result.p99_ms)} | "
            f"{_format_float(result.throughput_rps)} | "
            f"{status} |"
        )

    lines.append("")
    failed = [
        result.scenario
        for result in results
        if result.failure_count > 0 or math.isnan(result.p95_ms) or result.p95_ms > threshold_ms
    ]
    if failed:
        lines.append(f"Scenarios failing threshold: {', '.join(failed)}")
    else:
        lines.append("All scenarios are within the configured p95 threshold and with zero failures.")
    lines.append("")
    return "\n".join(lines)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Summarize Locust CSV performance outputs.")
    parser.add_argument(
        "--input-dir",
        required=True,
        help="Directory containing files generated by --csv (e.g. load-50-users_stats.csv).",
    )
    parser.add_argument(
        "--output",
        default="artifacts/performance/summary.md",
        help="Output markdown path.",
    )
    parser.add_argument(
        "--p95-threshold-ms",
        type=float,
        default=500.0,
        help="Maximum allowed p95 latency in milliseconds.",
    )
    parser.add_argument(
        "--strict",
        action="store_true",
        help="Exit with code 1 if any scenario fails threshold/failure criteria.",
    )
    return parser.parse_args()


def main() -> int:
    args = parse_args()
    input_dir = Path(args.input_dir)
    output_path = Path(args.output)

    stats_files = sorted(input_dir.glob("*_stats.csv"))
    if not stats_files:
        raise FileNotFoundError(f"No *_stats.csv files found in {input_dir}")

    results = [_load_scenario_result(path) for path in stats_files]
    markdown = _build_markdown(results, threshold_ms=args.p95_threshold_ms)

    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(markdown, encoding="utf-8")

    if args.strict:
        has_failures = any(
            result.failure_count > 0
            or math.isnan(result.p95_ms)
            or result.p95_ms > args.p95_threshold_ms
            for result in results
        )
        return 1 if has_failures else 0
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
